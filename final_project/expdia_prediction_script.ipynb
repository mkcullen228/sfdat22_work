{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From Kaggle Competition. Expedia Hotel Recommendations\n",
    "# https://www.kaggle.com/c/expedia-hotel-recommendations\n",
    "\n",
    "## Load the data from expedia kaggle Challenge\n",
    "destinations = pd.read_csv('../Final_Project/data/destinations.csv') \n",
    "# Read data into pandas and explore\n",
    "# expedia = pd.read_csv('../Final_Project/data/train.csv') # takes a LONG time to load the full dataset! \n",
    "expedia = pd.read_csv('../Final_Project/data/train.csv',nrows=10000) # test code with smaller set first for faster code check. \n",
    "# other dataset provided: testing dataset\n",
    "# df_test = pd.read_csv('../Final_Project/data/test.csv'); # will read this is later when/if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expedia Site Dataframe Shape\n",
      "(10000, 24)\n",
      "Destinations Dataframe Shape\n",
      "(62106, 150)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>d9</th>\n",
       "      <th>...</th>\n",
       "      <th>d140</th>\n",
       "      <th>d141</th>\n",
       "      <th>d142</th>\n",
       "      <th>d143</th>\n",
       "      <th>d144</th>\n",
       "      <th>d145</th>\n",
       "      <th>d146</th>\n",
       "      <th>d147</th>\n",
       "      <th>d148</th>\n",
       "      <th>d149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-1.897627</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-1.897627</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.082564</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.031597</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_destination_id        d1        d2        d3        d4        d5  \\\n",
       "0                    0 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657   \n",
       "1                    1 -2.181690 -2.181690 -2.181690 -2.082564 -2.181690   \n",
       "\n",
       "         d6        d7        d8        d9    ...         d140      d141  \\\n",
       "0 -1.897627 -2.198657 -2.198657 -1.897627    ...    -2.198657 -2.198657   \n",
       "1 -2.165028 -2.181690 -2.181690 -2.031597    ...    -2.165028 -2.181690   \n",
       "\n",
       "       d142      d143      d144      d145      d146      d147      d148  \\\n",
       "0 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657   \n",
       "1 -2.165028 -2.181690 -2.181690 -2.165028 -2.181690 -2.181690 -2.181690   \n",
       "\n",
       "       d149  \n",
       "0 -2.198657  \n",
       "1 -2.181690  \n",
       "\n",
       "[2 rows x 150 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'Expedia Site Dataframe Shape'\n",
    "print expedia.shape\n",
    "expedia.head(2)\n",
    "print 'Destinations Dataframe Shape'\n",
    "print destinations.shape\n",
    "destinations.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaination of Columns from https://www.kaggle.com/c/expedia-hotel-recommendations/data \n",
    "\n",
    "date_time - Timestamp - string\n",
    "site_name - ID of the Expedia point of sale - int\n",
    "posa_continent - ID of continent associated with site_name\t- int\n",
    "user_location_country - The ID of the country the customer is located - int\n",
    "user_location_region - The ID of the region the customer is located - int\n",
    "user_location_city - The ID of the city the customer is located - int\n",
    "orig_destination_distance - Physical distance between a hotel and a customer at the time of search. A null means the distance could not be calculated- double\n",
    "user_id - ID of user - int\n",
    "is_mobile - 1 when a user connected from a mobile device, 0 otherwise - tinyint\n",
    "is_package - 1 if the click/booking was generated as a part of a package, 0 otherwise - int\n",
    "channel  - \tID of a marketing channel\n",
    "srch_ci - Checkin date - string\n",
    "srch_co - Checkout date - string\n",
    "srch_adults_cnt - The number of adults specified in the hotel room - int\n",
    "srch_children_cnt - The number of (extra occupancy) children specified in the hotel room - int\n",
    "srch_rm_cnt - The number of hotel rooms specified in the search - int\n",
    "srch_destination_id - ID of the destination where the hotel search was performed - int\n",
    "srch_destination_type_id - Type of destination - int\n",
    "hotel_continent - Hotel continent - int\n",
    "hotel_country - Hotel country - int\n",
    "hotel_market - Hotel market - int\n",
    "is_booking - 1 if a booking, 0 if a click - tinyint\n",
    "cnt - Numer of similar events in the context of the same user session  -bigint\n",
    "hotel_cluster - ID of a hotel cluster - int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Size of Dataframe (10000, 24)\n",
      "Unique Users:  339\n",
      "Mean entries per user:  29.4985250737\n",
      "Number of entries where users book 777 total 10000\n",
      "Unique Hotel Cluter IDs:  100\n"
     ]
    }
   ],
   "source": [
    "# Print some info about dataset\n",
    "\n",
    "# user IDs. \n",
    "print 'Dataset Stats'\n",
    "print 'Size of Dataframe', expedia.shape\n",
    "\n",
    "# unique User counts. \n",
    "user = expedia.groupby('user_id').user_id.count()\n",
    "muser = user.mean()\n",
    "print 'Unique Users: ', len(user)\n",
    "print 'Mean entries per user: ', muser\n",
    "\n",
    "# Number of bookings vs. other entries. \n",
    "lbook = len(expedia.loc[(expedia['is_booking']  == 1)])\n",
    "num_book = expedia.groupby('is_booking').is_booking.count()\n",
    "print 'Number of entries where users book', lbook, 'total', len(expedia)\n",
    "\n",
    "# unique hotel cluster counts. \n",
    "hc = expedia.groupby('hotel_cluster').hotel_cluster.count()\n",
    "print 'Unique Hotel Cluter IDs: ', len(hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add a column for the epoch time to dataset. Need to do this before time is changed from a string to a date time\n",
    "import time, os\n",
    "epochs = []\n",
    "d = expedia.date_time\n",
    "p='%Y-%m-%d %H:%M:%S'\n",
    "for dts in d:\n",
    "    epoch = int(time.mktime(time.strptime(dts,p)))\n",
    "    epochs.append(epoch)\n",
    "expedia['time_epoch'] = epochs\n",
    "# expedia.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define function to find the day of the week. \n",
    "# Monday = 1, Sunday = 7\n",
    "def find_dow(date_col):\n",
    "    dow = []\n",
    "    for d in date_col: \n",
    "        dow.append(d.isoweekday()) \n",
    "    return dow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_name</th>\n",
       "      <th>posa_continent</th>\n",
       "      <th>user_location_country</th>\n",
       "      <th>user_location_region</th>\n",
       "      <th>user_location_city</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_mobile</th>\n",
       "      <th>is_package</th>\n",
       "      <th>...</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>hotel_market</th>\n",
       "      <th>hotel_cluster</th>\n",
       "      <th>time_epoch</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dow_search</th>\n",
       "      <th>dow_ci</th>\n",
       "      <th>dow_co</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-11 07:46:59</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "      <td>1407768419</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-11 08:22:12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "      <td>1407770532</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date_time  site_name  posa_continent  user_location_country  \\\n",
       "0 2014-08-11 07:46:59          2               3                     66   \n",
       "1 2014-08-11 08:22:12          2               3                     66   \n",
       "\n",
       "   user_location_region  user_location_city  orig_destination_distance  \\\n",
       "0                   348               48862                  2234.2641   \n",
       "1                   348               48862                  2234.2641   \n",
       "\n",
       "   user_id  is_mobile  is_package   ...    hotel_country hotel_market  \\\n",
       "0       12          0           1   ...               50          628   \n",
       "1       12          0           1   ...               50          628   \n",
       "\n",
       "  hotel_cluster  time_epoch  year  month  day  dow_search  dow_ci  dow_co  \n",
       "0             1  1407768419  2014      8   11           1     3.0     7.0  \n",
       "1             1  1407770532  2014      8   11           1     5.0     2.0  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding Time Feature columns to Dataset \n",
    "# TODO replace NAN in check-in and check-out columns\n",
    "\n",
    "expedia['date_time'] = pd.to_datetime(expedia['date_time'])\n",
    "expedia['year'] = expedia['date_time'].dt.year\n",
    "expedia['month'] = expedia['date_time'].dt.month\n",
    "expedia['day'] = expedia['date_time'].dt.day\n",
    "\n",
    "# Adding Day of the week the search occured\n",
    "# Monday = 1, Sunday = 7\n",
    "date_time = expedia.date_time\n",
    "dow = find_dow(date_time)\n",
    "expedia['dow_search'] = dow\n",
    "\n",
    "# Adding Day of the week check-in date\n",
    "expedia['srch_ci'] = pd.to_datetime(expedia['srch_ci'])\n",
    "date_chi = expedia.srch_ci\n",
    "dow = find_dow(date_chi)\n",
    "expedia['dow_ci'] = dow\n",
    "\n",
    "# Adding Day of the week check-out date\n",
    "expedia['srch_co'] = pd.to_datetime(expedia['srch_co'])\n",
    "date_co = expedia.srch_co\n",
    "dow = find_dow(date_co)\n",
    "expedia['dow_co'] = dow\n",
    "\n",
    "\n",
    "expedia.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding a feature for is_weekend_trip column\n",
    "# definition: Check-in between Wednesday - Friday and Checkout Sunday - Tuesday  will be a weekend trip. \n",
    "# 1 = weekend, 0 = during week trip. \n",
    "# dow_ci = expedia.dow_ci\n",
    "# dow_co = expedia.dow_co\n",
    "# wt = np.zeros(len(dow_ci))\n",
    "\n",
    "# for i in wt:\n",
    "    # if dow_ci >= 3 and dow_ci <= 6:\n",
    "    #     if dow_co <= 6 and dow_co >= 2:\n",
    "    #         i = 1\n",
    "\n",
    "# expedia['is_weekend_trip'] = wt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " feature ideas: \n",
    " number or clicks before purchase\n",
    " repeat clicks? user visits same hotel cluster again \n",
    " \n",
    " if user books more than one hotel - is it in the same cluster, same location? \n",
    " time on site searching column (from time_epoch)\n",
    " \n",
    " add dictionary look up for user.\n",
    " Recommendation engine? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_name</th>\n",
       "      <th>posa_continent</th>\n",
       "      <th>user_location_country</th>\n",
       "      <th>user_location_region</th>\n",
       "      <th>user_location_city</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_mobile</th>\n",
       "      <th>is_package</th>\n",
       "      <th>...</th>\n",
       "      <th>hotel_cluster</th>\n",
       "      <th>time_epoch</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dow_search</th>\n",
       "      <th>dow_ci</th>\n",
       "      <th>dow_co</th>\n",
       "      <th>is_family</th>\n",
       "      <th>booking_clust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-11 07:46:59</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1407768419</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-11 08:22:12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1407770532</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date_time  site_name  posa_continent  user_location_country  \\\n",
       "0 2014-08-11 07:46:59          2               3                     66   \n",
       "1 2014-08-11 08:22:12          2               3                     66   \n",
       "\n",
       "   user_location_region  user_location_city  orig_destination_distance  \\\n",
       "0                   348               48862                  2234.2641   \n",
       "1                   348               48862                  2234.2641   \n",
       "\n",
       "   user_id  is_mobile  is_package      ...        hotel_cluster  time_epoch  \\\n",
       "0       12          0           1      ...                    1  1407768419   \n",
       "1       12          0           1      ...                    1  1407770532   \n",
       "\n",
       "   year  month  day  dow_search  dow_ci  dow_co  is_family  booking_clust  \n",
       "0  2014      8   11           1     3.0     7.0          0              0  \n",
       "1  2014      8   11           1     5.0     2.0          0            101  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding feature columns to dataset. \n",
    "\n",
    "# if there are children - making a binary column of family\n",
    "is_family = np.where(expedia.srch_children_cnt >= 1, 1, 0)\n",
    "expedia['is_family'] = is_family\n",
    "\n",
    "# Adding column for search and is booking. \n",
    "# booking cluster  = 100 + cluster ID if booked,  0 if not booking\n",
    "expedia['booking_clust'] = np.where(expedia.is_booking == 1,(100+ expedia.hotel_cluster) ,0)\n",
    "\n",
    "expedia.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time                       0\n",
       "site_name                       0\n",
       "posa_continent                  0\n",
       "user_location_country           0\n",
       "user_location_region            0\n",
       "user_location_city              0\n",
       "orig_destination_distance    3729\n",
       "user_id                         0\n",
       "is_mobile                       0\n",
       "is_package                      0\n",
       "channel                         0\n",
       "srch_ci                         7\n",
       "srch_co                         7\n",
       "srch_adults_cnt                 0\n",
       "srch_children_cnt               0\n",
       "srch_rm_cnt                     0\n",
       "srch_destination_id             0\n",
       "srch_destination_type_id        0\n",
       "is_booking                      0\n",
       "cnt                             0\n",
       "hotel_continent                 0\n",
       "hotel_country                   0\n",
       "hotel_market                    0\n",
       "hotel_cluster                   0\n",
       "time_epoch                      0\n",
       "year                            0\n",
       "month                           0\n",
       "day                             0\n",
       "dow_search                      0\n",
       "dow_ci                          7\n",
       "dow_co                          7\n",
       "is_family                       0\n",
       "booking_clust                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expedia.isnull().sum()\n",
    "# orig_destination_distance,  srch_ci, srch_co,  contains null values\n",
    "# expedia.loc[pd.isnull(expedia['orig_destination_distance'])] = np.nan\n",
    "# expedia.orig_destination_distance\n",
    "expedia.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict if a person is booking or not. \n",
    "# We do not care what hotel cluster a person is looking at unless they book. \n",
    "\n",
    "# print expedia.hotel_cluster.max()\n",
    "# print expedia.hotel_cluster.min()\n",
    "# expedia.corr()\n",
    "\n",
    "\n",
    "# labels = expedia.columns # features to train with \n",
    "# full list\n",
    "# X = [ \n",
    "#     { 'date_time', 'site_name', 'posa_continent', 'user_location_country',\n",
    "#        'user_location_region', 'user_location_city',\n",
    "#        'orig_destination_distance', 'user_id', 'is_mobile', 'is_package',\n",
    "#        'channel', 'srch_ci', 'srch_co', 'srch_adults_cnt',\n",
    "#        'srch_children_cnt', 'srch_rm_cnt', 'srch_destination_id',\n",
    "#        'srch_destination_type_id', 'is_booking', 'cnt', 'hotel_continent',\n",
    "#        'hotel_country', 'hotel_market', 'hotel_cluster'\n",
    "#      }]\n",
    "\n",
    "X = expedia.drop(['is_booking','date_time','srch_ci','srch_co','orig_destination_distance'], axis = 1) # features\n",
    "feature_cols = X.columns # get colnames for use later\n",
    "# np.array(expedia) \n",
    "target = expedia.is_booking # y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add a null model for comparison of baseline \n",
    "\n",
    "mo_target = target.mode() # guess 0 - they do not book all the time. \n",
    "# pred = np.zero(len(expdedia),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-237-de8b65c04c19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mpreds_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mcullen/anaconda/lib/python2.7/site-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    776\u001b[0m         \"\"\"\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mcullen/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    508\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    509\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/mcullen/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    396\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mcullen/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     52\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     53\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 54\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# train a classification model with existing columns\n",
    "# trying KNN and log reg to start. \n",
    "# Note: do not need to test_train_split because Kaggle provides a separate traing set. \n",
    "\n",
    "# knn\n",
    "# k = 3\n",
    "# knn = KNeighborsClassifier(n_neighbors=k)\n",
    "# knn.fit(X, target)\n",
    "# knn.score(X, target)\n",
    "\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "# k_range = range(2, 30, 1)\n",
    "# param_grid = dict(n_neighbors=k_range)\n",
    "# grid = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "# grid.fit(X_train, y_train)\n",
    "# grid.grid_scores_\n",
    "# grid_mean_scores = [result[1] for result in grid.grid_scores_] # get scores from grid.grid_scores_\n",
    "# visualize results\n",
    "# plt.figure()\n",
    "# plt.plot(k_range, grid_mean_scores)\n",
    "\n",
    "# retraining with added column\n",
    "# knn\n",
    "k = 3\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X, target)\n",
    "knn.score(X, target)\n",
    "preds_knn = knn.predict(X)\n",
    "print 'Accuracy for KNN model'\n",
    "print accuracy_score(target, preds_knn)\n",
    "print 'KNN Confusion Matrix'\n",
    "print metrics.confusion_matrix(target, preds_knn)\n",
    "target_names = ['Did not Book 0','Booked 1']\n",
    "print(classification_report(target, preds_knn, target_names=target_names))\n",
    "\n",
    "# test set \n",
    "# preds_knn = knn.predict(X_test)\n",
    "# print 'Accuracy for KNN model'\n",
    "# print accuracy_score(y_test, preds_knn)\n",
    "# print 'KNN Confusion Matrix'\n",
    "# print metrics.confusion_matrix(y_test, preds_knn)\n",
    "# print(classification_report(y_test, preds_knn, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Logistic Regression model\n",
      "0.9223\n",
      "Logistic Regression Confusion Matrix\n",
      "[[9223    0]\n",
      " [ 777    0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Did not Book 0       0.92      1.00      0.96      9223\n",
      "      Booked 1       0.00      0.00      0.00       777\n",
      "\n",
      "   avg / total       0.85      0.92      0.89     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mcullen/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# LogReg\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X, target)\n",
    "assorted_pred_class = logreg.predict(X)\n",
    "logregm = zip(feature_cols,logreg.coef_[0])\n",
    "preds_logreg = logreg.predict(X)\n",
    "print 'Accuracy for Logistic Regression model'\n",
    "print accuracy_score(target, preds_logreg)\n",
    "print 'Logistic Regression Confusion Matrix'\n",
    "print metrics.confusion_matrix(target, preds_logreg)\n",
    "print(classification_report(target, preds_logreg, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switching to predicting which cluster \n",
    "Assuming we can use first part to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(777, 24)\n"
     ]
    }
   ],
   "source": [
    "# for predicting which hotel cluster the person will book. \n",
    "\n",
    "# Select df only when the user is booking the hotel. \n",
    "# only look at when a person is booking. \n",
    "df_book = expedia.loc[expedia.is_booking == 1]\n",
    "print df_book.shape\n",
    "# df_book.corr()\n",
    "\n",
    "X = df_book.drop(['hotel_cluster','date_time','srch_ci','srch_co','orig_destination_distance'], axis = 1) # features\n",
    "target = df_book.hotel_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Null model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for KNN model\n",
      "0.418275418275\n",
      "KNN Confusion Matrix\n",
      "[[ 2  0  0 ...,  1  0  0]\n",
      " [ 0 11  0 ...,  0  0  0]\n",
      " [ 0  1  5 ...,  0  0  0]\n",
      " ..., \n",
      " [ 0  0  0 ...,  5  0  0]\n",
      " [ 0  0  0 ...,  0  0  0]\n",
      " [ 0  0  0 ...,  0  0  2]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.29      0.67      0.40         3\n",
      "          1       0.31      1.00      0.47        11\n",
      "          2       0.29      0.83      0.43         6\n",
      "          3       0.57      1.00      0.73         4\n",
      "          4       0.42      1.00      0.59         5\n",
      "          5       0.31      0.71      0.43         7\n",
      "          6       0.41      1.00      0.58        16\n",
      "          7       0.31      0.92      0.47        12\n",
      "          8       0.40      0.50      0.44         4\n",
      "          9       0.50      0.40      0.44         5\n",
      "         10       0.38      1.00      0.55         6\n",
      "         11       0.45      0.83      0.59         6\n",
      "         12       0.64      0.82      0.72        11\n",
      "         13       0.52      0.79      0.63        14\n",
      "         14       0.43      0.75      0.55         4\n",
      "         15       0.62      0.80      0.70        10\n",
      "         16       0.40      0.77      0.53        13\n",
      "         17       0.33      0.67      0.44         3\n",
      "         18       0.36      0.71      0.48        17\n",
      "         19       0.45      0.71      0.56         7\n",
      "         20       0.38      1.00      0.55         3\n",
      "         21       0.35      0.75      0.47        24\n",
      "         22       0.31      0.57      0.40         7\n",
      "         23       0.39      0.64      0.48        11\n",
      "         24       0.50      1.00      0.67         1\n",
      "         25       0.31      0.42      0.36        12\n",
      "         26       0.25      0.75      0.38         4\n",
      "         28       0.50      0.67      0.57        21\n",
      "         29       0.39      0.88      0.54         8\n",
      "         30       0.50      0.20      0.29         5\n",
      "         31       0.25      0.40      0.31         5\n",
      "         32       0.40      0.36      0.38        11\n",
      "         33       0.50      0.44      0.47        16\n",
      "         34       0.29      0.40      0.33         5\n",
      "         35       0.00      0.00      0.00         1\n",
      "         36       0.38      0.38      0.38        13\n",
      "         37       0.40      0.33      0.36         6\n",
      "         38       0.67      0.40      0.50         5\n",
      "         39       0.00      0.00      0.00         6\n",
      "         40       0.27      0.35      0.31        17\n",
      "         41       0.56      0.50      0.53        10\n",
      "         42       0.67      0.47      0.55        17\n",
      "         43       0.67      0.40      0.50        10\n",
      "         44       0.50      0.50      0.50         4\n",
      "         45       0.40      0.67      0.50         3\n",
      "         46       0.22      0.22      0.22         9\n",
      "         47       0.50      0.08      0.14        12\n",
      "         48       0.28      0.24      0.26        21\n",
      "         49       0.50      0.25      0.33         4\n",
      "         50       0.50      0.29      0.36         7\n",
      "         51       0.67      0.50      0.57         8\n",
      "         52       0.25      0.33      0.29         3\n",
      "         53       1.00      0.50      0.67         4\n",
      "         54       0.75      0.50      0.60         6\n",
      "         55       0.50      0.33      0.40         3\n",
      "         56       0.50      0.29      0.36         7\n",
      "         57       0.50      0.50      0.50         8\n",
      "         58       0.33      0.14      0.20         7\n",
      "         59       0.25      0.09      0.13        11\n",
      "         60       0.00      0.00      0.00         4\n",
      "         61       0.25      0.12      0.17         8\n",
      "         62       0.33      0.20      0.25         5\n",
      "         63       0.67      0.29      0.40         7\n",
      "         64       0.00      0.00      0.00         6\n",
      "         65       0.00      0.00      0.00         5\n",
      "         66       0.00      0.00      0.00         2\n",
      "         67       0.67      0.40      0.50         5\n",
      "         68       0.57      0.27      0.36        15\n",
      "         69       0.00      0.00      0.00         1\n",
      "         70       0.40      0.18      0.25        11\n",
      "         71       0.00      0.00      0.00         1\n",
      "         72       1.00      0.10      0.18        10\n",
      "         73       0.75      0.23      0.35        13\n",
      "         74       0.00      0.00      0.00         1\n",
      "         75       0.00      0.00      0.00         2\n",
      "         76       1.00      0.40      0.57         5\n",
      "         77       0.40      0.22      0.29         9\n",
      "         78       0.00      0.00      0.00         8\n",
      "         80       0.00      0.00      0.00         2\n",
      "         81       0.00      0.00      0.00        11\n",
      "         82       0.00      0.00      0.00        11\n",
      "         83       0.00      0.00      0.00         7\n",
      "         84       0.00      0.00      0.00         2\n",
      "         85       0.00      0.00      0.00         3\n",
      "         86       0.50      0.33      0.40         6\n",
      "         87       0.00      0.00      0.00         2\n",
      "         88       0.50      0.33      0.40         3\n",
      "         89       0.00      0.00      0.00         3\n",
      "         90       1.00      0.33      0.50         6\n",
      "         91       0.67      0.29      0.40        35\n",
      "         92       0.00      0.00      0.00         2\n",
      "         93       0.00      0.00      0.00         1\n",
      "         94       0.00      0.00      0.00         6\n",
      "         95       0.83      0.22      0.34        23\n",
      "         96       0.00      0.00      0.00         4\n",
      "         97       0.56      0.38      0.45        13\n",
      "         98       0.00      0.00      0.00         6\n",
      "         99       0.67      0.14      0.24        14\n",
      "\n",
      "avg / total       0.43      0.42      0.37       777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X, target)\n",
    "knn.score(X, target)\n",
    "preds_knn = knn.predict(X)\n",
    "print 'Accuracy for KNN model'\n",
    "print accuracy_score(target, preds_knn)\n",
    "print 'KNN Confusion Matrix'\n",
    "print metrics.confusion_matrix(target, preds_knn)\n",
    "# target_names = ['Did not Book 0','Booked 1']\n",
    "# print(classification_report(target, preds_knn, target_names=target_names))\n",
    "print(classification_report(target, preds_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Logistic Regression model\n",
      "0.189189189189\n",
      "Logistic Regression Confusion Matrix\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 7 0 ..., 0 0 0]\n",
      " [0 0 2 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 2 0 1]\n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 1 0 4]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         3\n",
      "          1       0.26      0.64      0.37        11\n",
      "          2       0.29      0.33      0.31         6\n",
      "          3       0.00      0.00      0.00         4\n",
      "          4       0.00      0.00      0.00         5\n",
      "          5       0.33      0.14      0.20         7\n",
      "          6       0.19      0.19      0.19        16\n",
      "          7       0.11      0.08      0.10        12\n",
      "          8       0.00      0.00      0.00         4\n",
      "          9       0.14      0.20      0.17         5\n",
      "         10       0.00      0.00      0.00         6\n",
      "         11       0.00      0.00      0.00         6\n",
      "         12       0.11      0.09      0.10        11\n",
      "         13       0.44      0.50      0.47        14\n",
      "         14       0.00      0.00      0.00         4\n",
      "         15       0.33      0.20      0.25        10\n",
      "         16       0.00      0.00      0.00        13\n",
      "         17       0.20      0.33      0.25         3\n",
      "         18       0.00      0.00      0.00        17\n",
      "         19       0.50      0.14      0.22         7\n",
      "         20       0.25      0.33      0.29         3\n",
      "         21       0.09      0.17      0.12        24\n",
      "         22       0.00      0.00      0.00         7\n",
      "         23       0.13      0.18      0.15        11\n",
      "         24       0.33      1.00      0.50         1\n",
      "         25       0.20      0.17      0.18        12\n",
      "         26       0.50      0.25      0.33         4\n",
      "         28       0.22      0.29      0.25        21\n",
      "         29       0.43      0.75      0.55         8\n",
      "         30       0.00      0.00      0.00         5\n",
      "         31       0.00      0.00      0.00         5\n",
      "         32       0.00      0.00      0.00        11\n",
      "         33       0.20      0.06      0.10        16\n",
      "         34       0.00      0.00      0.00         5\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       0.19      0.31      0.24        13\n",
      "         37       0.00      0.00      0.00         6\n",
      "         38       0.25      0.40      0.31         5\n",
      "         39       0.33      0.33      0.33         6\n",
      "         40       0.00      0.00      0.00        17\n",
      "         41       0.12      0.10      0.11        10\n",
      "         42       0.00      0.00      0.00        17\n",
      "         43       0.20      0.20      0.20        10\n",
      "         44       0.00      0.00      0.00         4\n",
      "         45       1.00      0.33      0.50         3\n",
      "         46       0.17      0.11      0.13         9\n",
      "         47       0.00      0.00      0.00        12\n",
      "         48       0.06      0.05      0.05        21\n",
      "         49       0.25      0.75      0.38         4\n",
      "         50       0.00      0.00      0.00         7\n",
      "         51       0.09      0.12      0.11         8\n",
      "         52       1.00      1.00      1.00         3\n",
      "         53       0.43      0.75      0.55         4\n",
      "         54       0.31      0.67      0.42         6\n",
      "         55       0.00      0.00      0.00         3\n",
      "         56       0.43      0.43      0.43         7\n",
      "         57       0.17      0.12      0.14         8\n",
      "         58       0.43      0.43      0.43         7\n",
      "         59       1.00      0.09      0.17        11\n",
      "         60       1.00      0.25      0.40         4\n",
      "         61       0.29      0.25      0.27         8\n",
      "         62       0.00      0.00      0.00         5\n",
      "         63       0.40      0.29      0.33         7\n",
      "         64       0.14      0.17      0.15         6\n",
      "         65       0.29      0.40      0.33         5\n",
      "         66       1.00      1.00      1.00         2\n",
      "         67       0.40      0.80      0.53         5\n",
      "         68       0.00      0.00      0.00        15\n",
      "         69       0.50      1.00      0.67         1\n",
      "         70       0.00      0.00      0.00        11\n",
      "         71       1.00      1.00      1.00         1\n",
      "         72       0.00      0.00      0.00        10\n",
      "         73       0.00      0.00      0.00        13\n",
      "         74       1.00      1.00      1.00         1\n",
      "         75       0.00      0.00      0.00         2\n",
      "         76       0.31      1.00      0.48         5\n",
      "         77       0.67      0.22      0.33         9\n",
      "         78       0.00      0.00      0.00         8\n",
      "         80       0.50      1.00      0.67         2\n",
      "         81       0.00      0.00      0.00        11\n",
      "         82       0.20      0.09      0.13        11\n",
      "         83       0.12      0.14      0.13         7\n",
      "         84       0.25      1.00      0.40         2\n",
      "         85       0.33      0.33      0.33         3\n",
      "         86       0.50      0.33      0.40         6\n",
      "         87       1.00      1.00      1.00         2\n",
      "         88       0.00      0.00      0.00         3\n",
      "         89       0.25      0.67      0.36         3\n",
      "         90       0.29      0.33      0.31         6\n",
      "         91       0.10      0.31      0.16        35\n",
      "         92       0.00      0.00      0.00         2\n",
      "         93       0.00      0.00      0.00         1\n",
      "         94       0.00      0.00      0.00         6\n",
      "         95       0.09      0.13      0.10        23\n",
      "         96       0.00      0.00      0.00         4\n",
      "         97       0.10      0.15      0.12        13\n",
      "         98       0.00      0.00      0.00         6\n",
      "         99       0.19      0.29      0.23        14\n",
      "\n",
      "avg / total       0.18      0.19      0.16       777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X, target)\n",
    "assorted_pred_class = logreg.predict(X)\n",
    "logregm = zip(feature_cols,logreg.coef_[0])\n",
    "preds_logreg = logreg.predict(X)\n",
    "print 'Accuracy for Logistic Regression model'\n",
    "print accuracy_score(target, preds_logreg)\n",
    "print 'Logistic Regression Confusion Matrix'\n",
    "print metrics.confusion_matrix(target, preds_logreg)\n",
    "print(classification_report(target, preds_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test Full model\n",
    "# combination of best first classification + predicting hotel cluster. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
